/**
 * Gemini API Utilities
 * F√ºr OCR/Vision und Image Generation
 */

import { GoogleGenerativeAI } from '@google/generative-ai';
import { ENV } from './env.mjs';
import fetch from 'node-fetch';

const genAI = new GoogleGenerativeAI(ENV.GEMINI_API_KEY || '');

/**
 * PDF-Extraktion mit Gemini 2.5 Pro
 * Direkte PDF-Verarbeitung ohne JPEG-Konvertierung
 */
async function performOCRWithGemini(fileUrl) {
  if (!ENV.GEMINI_API_KEY) {
    throw new Error('GEMINI_API_KEY nicht gesetzt');
  }

  try {
    console.log(`üîç Starte PDF-Extraktion mit Gemini 2.5 Pro f√ºr ${fileUrl}...`);

    const fileResponse = await fetch(fileUrl);
    if (!fileResponse.ok) {
      throw new Error(`Fehler beim Laden der Datei: ${fileResponse.statusText}`);
    }

    const contentType = fileResponse.headers.get('content-type') || '';
    const isPDF = contentType.includes('pdf') || fileUrl.toLowerCase().endsWith('.pdf');
    
    const fileBuffer = await fileResponse.arrayBuffer();
    const fileBase64 = Buffer.from(fileBuffer).toString('base64');
    
    // Versuche Gemini 2.5 Pro, fallback auf 1.5 Pro Vision
    const modelsToTry = [
      'gemini-2.5-pro',
      'gemini-2.0-flash-exp',
      'gemini-1.5-pro',
    ];

    let extractedText = '';
    let pages = 1;
    let lastError = null;

    for (const modelName of modelsToTry) {
      try {
        console.log(`üìÑ Versuche Modell: ${modelName}...`);
        
        const model = genAI.getGenerativeModel({ 
          model: modelName,
        });

        const mimeType = isPDF ? 'application/pdf' : contentType || 'image/jpeg';
        
        const prompt = `Analysiere dieses Dokument vollst√§ndig und extrahiere ALLEN Text, alle Aufgaben, Fragen, Antworten und Zahlen.

WICHTIG:
- Extrahiere den Text genau so, wie er im Dokument erscheint
- Behalte die Struktur bei (√úberschriften, Abs√§tze, Listen)
- Erkenne alle Lernaufgaben und √úbungen
- Erkenne die Art des Arbeitsblatts (z.B. Mathematik-√úbungen, Deutsch-Aufgaben, etc.)
- Erkenne die Aufgabenformate (Multiple-Choice, L√ºckentext, Zuordnung, etc.)
- Erkenne L√∂sungen und Antworten wenn vorhanden

Gib den vollst√§ndigen Text zur√ºck, strukturiert und vollst√§ndig.`;

        const result = await model.generateContent([
          {
            inlineData: {
              data: fileBase64,
              mimeType: mimeType,
            },
          },
          { text: prompt },
        ]);

        const response = await result.response;
        extractedText = response.text();
        
        // Sch√§tze Seitenzahl basierend auf Textl√§nge
        pages = Math.max(1, Math.ceil(extractedText.length / 2000));
        
        console.log(`‚úÖ Gemini ${modelName} Text extrahiert: ${extractedText.length} Zeichen, gesch√§tzt ${pages} Seiten`);
        break; // Erfolg, breche ab
      } catch (modelError) {
        console.warn(`‚ö†Ô∏è Modell ${modelName} nicht verf√ºgbar:`, modelError.message);
        lastError = modelError;
        continue;
      }
    }

    if (!extractedText) {
      throw lastError || new Error('Alle Gemini-Modelle fehlgeschlagen');
    }

    // Confidence basierend auf Textl√§nge und Qualit√§t
    const confidence = extractedText.length > 200 ? 0.95 : extractedText.length > 50 ? 0.85 : 0.7;

    console.log(`‚úÖ Gemini OCR abgeschlossen: ${extractedText.length} Zeichen extrahiert, ${pages} Seiten`);

    return {
      text: extractedText,
      confidence,
      pages,
      mimeType: isPDF ? 'application/pdf' : contentType,
      method: 'gemini',
    };
  } catch (error) {
    console.error('‚ùå Fehler bei Gemini OCR:', error);
    throw new Error(`Gemini OCR-Fehler: ${error.message}`);
  }
}

/**
 * OCR mit Gemini 2.5 Pro oder GPT-5 f√ºr bessere PDF-Verarbeitung
 * Analysiert PDF direkt ohne JPEG-Konvertierung
 * Verwendet Gemini 2.5 Pro als prim√§res Modell (kostenlos/kosteng√ºnstig mit Google)
 * Fallback auf GPT-5 oder GPT-4o falls Gemini nicht verf√ºgbar
 */
export async function performOCR(fileUrl) {
  // Versuche zuerst Gemini 2.5 Pro (kostenlos/kosteng√ºnstig, gute PDF-Unterst√ºtzung)
  if (ENV.GEMINI_API_KEY) {
    try {
      return await performOCRWithGemini(fileUrl);
    } catch (geminiError) {
      console.warn('‚ö†Ô∏è Gemini OCR fehlgeschlagen, versuche Fallback:', geminiError.message);
      // Fallback auf OpenAI
    }
  }

  // Fallback: OpenAI GPT-5 oder GPT-4o
  const OpenAI = (await import('openai')).default;
  const openai = new OpenAI({
    apiKey: ENV.OPENAI_API_KEY || '',
  });

  if (!ENV.OPENAI_API_KEY) {
    throw new Error('Weder GEMINI_API_KEY noch OPENAI_API_KEY gesetzt');
  }

  try {
    console.log(`üîç Starte OCR mit GPT-4 Vision f√ºr ${fileUrl}...`);

    const fileResponse = await fetch(fileUrl);
    if (!fileResponse.ok) {
      throw new Error(`Fehler beim Laden der Datei: ${fileResponse.statusText}`);
    }

    const contentType = fileResponse.headers.get('content-type') || '';
    const isPDF = contentType.includes('pdf') || fileUrl.toLowerCase().endsWith('.pdf');
    
    let extractedText = '';
    let pages = 1;

    if (isPDF) {
      // F√ºr PDFs: Verwende pdf-parse f√ºr Text-PDFs, GPT-4 Vision f√ºr Bild-PDFs
      console.log('üìÑ PDF erkannt - versuche Text-Extraktion...');
      
      try {
        const pdf = (await import('pdf-parse')).default;
        const pdfBuffer = await fileResponse.arrayBuffer();
        const pdfData = await pdf(Buffer.from(pdfBuffer));
        
        extractedText = pdfData.text;
        pages = pdfData.numpages;
        
        console.log(`‚úÖ PDF-Text extrahiert: ${extractedText.length} Zeichen, ${pages} Seiten`);
        
        // Falls wenig Text extrahiert wurde, k√∂nnte es ein Bild-PDF sein
        if (extractedText.length < 200 && pages > 0) {
          console.log('‚ö†Ô∏è Wenig Text extrahiert - k√∂nnte ein Bild-PDF sein. Verwende GPT-4 Vision f√ºr erste Seite...');
          // Verwende GPT-4 Vision f√ºr erste Seite
          const imageBuffer = await fileResponse.arrayBuffer();
          const imageBase64 = Buffer.from(imageBuffer).toString('base64');
          
          const visionResponse = await openai.chat.completions.create({
            model: 'gpt-4o',
            messages: [
              {
                role: 'user',
                content: [
                  {
                    type: 'text',
                    text: `Extrahiere ALLEN Text aus diesem PDF-Dokument. Gib den kompletten Text zur√ºck, so wie er auf dem Dokument erscheint. Erhalte die Struktur und alle Details.`,
                  },
                  {
                    type: 'image_url',
                    image_url: {
                      url: `data:application/pdf;base64,${imageBase64}`,
                    },
                  },
                ],
              },
            ],
            max_tokens: 4000,
          });
          
          const visionText = visionResponse.choices[0]?.message?.content || '';
          if (visionText.length > extractedText.length) {
            extractedText = visionText;
            console.log(`‚úÖ GPT-4 Vision Text extrahiert: ${extractedText.length} Zeichen`);
          }
        }
      } catch (pdfError) {
        console.warn('‚ö†Ô∏è pdf-parse fehlgeschlagen, verwende GPT-4 Vision...', pdfError.message);
        // Fallback: Verwende GPT-4 Vision direkt
        const imageBuffer = await fileResponse.arrayBuffer();
        const imageBase64 = Buffer.from(imageBuffer).toString('base64');
        
        const visionResponse = await openai.chat.completions.create({
          model: 'gpt-4o',
          messages: [
            {
              role: 'user',
              content: [
                {
                  type: 'text',
                  text: `Extrahiere ALLEN Text aus diesem PDF-Dokument. Gib den kompletten Text zur√ºck, so wie er auf dem Dokument erscheint. Erhalte die Struktur, alle Aufgaben, Fragen, Antworten und Zahlen.`,
                },
                {
                  type: 'image_url',
                  image_url: {
                    url: `data:application/pdf;base64,${imageBase64}`,
                  },
                },
              ],
            },
          ],
          max_tokens: 4000,
        });
        
        extractedText = visionResponse.choices[0]?.message?.content || '';
        pages = 1; // Sch√§tzung
      }
    } else {
      // F√ºr Bilder: Verwende GPT-4 Vision
      const imageBuffer = await fileResponse.arrayBuffer();
      const imageBase64 = Buffer.from(imageBuffer).toString('base64');
      const mimeType = contentType || 'image/jpeg';

      const visionResponse = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: `Extrahiere ALLEN Text aus diesem Bild. Gib den kompletten Text zur√ºck, so wie er auf dem Dokument erscheint. Erhalte die Struktur, alle Aufgaben, Fragen, Antworten und Zahlen.`,
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:${mimeType};base64,${imageBase64}`,
                },
              },
            ],
          },
        ],
        max_tokens: 4000,
      });

      extractedText = visionResponse.choices[0]?.message?.content || '';
    }

    // Confidence basierend auf Textl√§nge sch√§tzen
    const confidence = extractedText.length > 200 ? 0.9 : extractedText.length > 50 ? 0.8 : 0.6;

    console.log(`‚úÖ OCR abgeschlossen: ${extractedText.length} Zeichen extrahiert, ${pages} Seiten`);

    return {
      text: extractedText,
      confidence,
      pages,
      mimeType: isPDF ? 'application/pdf' : contentType,
    };
  } catch (error) {
    console.error('‚ùå Fehler bei OCR:', error);
    throw new Error(`OCR-Fehler: ${error.message}`);
  }
}

/**
 * Bild mit Gemini Image Generation erstellen
 * Generiert ein Bild basierend auf einem Prompt
 */
export async function generateImage(prompt, subject, grade) {
  if (!ENV.GEMINI_API_KEY) {
    throw new Error('GEMINI_API_KEY nicht gesetzt');
  }

  try {
    console.log(`üé® Generiere Bild: ${prompt.substring(0, 50)}...`);

    // Gemini kann aktuell keine Bilder generieren, aber wir k√∂nnen die Imagen API verwenden
    // F√ºr jetzt: Verwende einen Placeholder-Service oder speichere den Prompt
    // Sp√§ter: Integration mit Gemini Imagen oder alternativem Service

    // TODO: Wenn Gemini Imagen verf√ºgbar ist, hier implementieren
    // F√ºr jetzt: Return null und speichere nur den Prompt
    // Der Prompt kann sp√§ter verwendet werden, wenn Image Generation verf√ºgbar ist

    console.log(`‚ö†Ô∏è Bild-Generierung noch nicht vollst√§ndig implementiert. Prompt gespeichert.`);

    return {
      imageUrl: null, // Wird sp√§ter generiert
      prompt: prompt,
      needsGeneration: true,
    };
  } catch (error) {
    console.error('‚ùå Fehler bei Bild-Generierung:', error);
    return {
      imageUrl: null,
      prompt: prompt,
      needsGeneration: true,
      error: error.message,
    };
  }
}

/**
 * Bild analysieren und beschreiben
 * Erkennt Objekte, Struktur, etc.
 */
export async function analyzeImage(fileUrl) {
  if (!ENV.GEMINI_API_KEY) {
    throw new Error('GEMINI_API_KEY nicht gesetzt');
  }

  try {
    console.log(`üîç Analysiere Bild: ${fileUrl}...`);

    const imageResponse = await fetch(fileUrl);
    if (!imageResponse.ok) {
      throw new Error(`Fehler beim Laden des Bildes: ${imageResponse.statusText}`);
    }

    const imageBuffer = await imageResponse.arrayBuffer();
    const imageBase64 = Buffer.from(imageBuffer).toString('base64');
    const contentType = imageResponse.headers.get('content-type') || 'image/jpeg';

    const model = genAI.getGenerativeModel({ model: 'gemini-1.5-pro-vision' });

    const prompt = `Analysiere dieses Bild detailliert f√ºr eine Lernaufgabe f√ºr Kinder der Klasse 1-4.

Beschreibe:
1. Was ist auf dem Bild zu sehen? (Objekte, Personen, Tiere, Zahlen, etc.)
2. Welche Farben sind dominant?
3. Welche mathematischen Elemente sind sichtbar? (Zahlen, Formen, Mengen)
4. Welche Lernaufgaben k√∂nnten daraus entstehen?
5. Ist das Bild kindgerecht und f√ºr Grundsch√ºler geeignet?

Gib eine strukturierte Beschreibung zur√ºck.`;

    const result = await model.generateContent([
      {
        inlineData: {
          data: imageBase64,
          mimeType: contentType,
        },
      },
      { text: prompt },
    ]);

    const response = await result.response;
    const analysis = response.text();

    console.log(`‚úÖ Bild-Analyse abgeschlossen`);

    return {
      description: analysis,
      hasMathElements: analysis.toLowerCase().includes('zahl') || analysis.toLowerCase().includes('rechnen'),
      hasObjects: analysis.toLowerCase().includes('objekt') || analysis.toLowerCase().includes('tier'),
      isChildFriendly: !analysis.toLowerCase().includes('nicht geeignet'),
    };
  } catch (error) {
    console.error('‚ùå Fehler bei Bild-Analyse:', error);
    throw new Error(`Bild-Analyse Fehler: ${error.message}`);
  }
}

